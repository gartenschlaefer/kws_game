# --
# config file for this project

# --
# general stuff

# change config in machine learning
config_changer:

  # enable
  enabled: False

  # mfcc mix
  change_mfcc_mix: False

  # change architectures
  change_archs: False

  # archs
  archs: ['conv-trad', 'conv-fstride', 'conv-jim']

  # adv evaluate both encoder decoder
  adv_both_coders: False


# --
# dataset config

datasets:

  # --
  # version description
  # 1: better onset detection
  # 2: energy frame onset detection
  # 3: data extraction with min energy and randomize onsets
  # 4: normalized features
  # 5: no energy features, detection on first mfcc, dataset shuffled

  # speech commands dataset
  speech_commands:

    # file extension for audio files
    file_ext: '.wav'

    # number of samples
    sample_num_normal: 16000
    sample_num_mininmal: 8000

    # path to speech command dataset
    #dataset_path: ignore/dataset/speech_commands_v0.01/
    dataset_path: ignore/dataset/speech_commands_v0.02/

    # shuffle wavs for dataset separation
    shuffle_wavs: True

    # extraction path
    extraction_path: ignore/dataset/_extracted/

    # paths to save training, testing and validation data
    set_folders:
      train: train/
      test: test/
      validation: validation/

    # split of dataset in training, test, eval (must be a prob. distribution)
    #split_percs: [0.8, 0.1, 0.1]
    split_percs:
      train: 0.8
      test: 0.1
      validation: 0.1

    # folder names
    wav_folder: wavs/
    annotation_folder: annotation/

    # plot path root
    plot_paths:
      main: _plots/
      examples_grid: _plots/grid/
      mfcc: _plots/mfcc/
      stats: _plots/stats/
      waveform: _plots/waveform/
      damaged_files: _plots/damaged_files/

    # enable plot of each feature extraction
    enable_plot: False

    # recreate all datasets (copy wavs to data_paths - not necessary except the dataset is changed)
    recreate: False
    clean_files: False

    # v1 all labels
    #all_labels: ['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']
    
    # v2 all labels
    all_labels: ['backward', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'follow', 'forward', 'four', 'go', 'happy', 'house', 'learn', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'visual', 'wow', 'yes', 'zero']

    # selected labels of the whole set
    #sel_labels: ['left', 'right', 'up', 'down', 'go']
    sel_labels: ['yes', 'no', 'left', 'go', 'down', 'off', 'right', 'stop', 'up', 'on']
    #sel_labels: ['bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']
    #sel_labels: ['backward', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'follow', 'forward', 'four', 'go', 'happy', 'house', 'learn', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'visual', 'wow', 'yes', 'zero']

    # add noise to dataset
    add_noise: True
    noise_label: '_noise'
    noise_data_folder: _background_noise_/

    # shift of noise window to extract noise samples [seconds]
    noise_shift_s: 0.110

    # add mixed to dataset
    add_mixed: True
    mixed_label: '_mixed'

    # validation and test file list (from dataset path)
    validation_file_list: validation_list.txt
    testing_file_list: testing_list.txt

    # version
    version_nr: 5

    # number of examples picked from dataset
    #n_examples: 10
    #n_examples: 500
    n_examples: 3500

    # file name for saved feature files
    mfcc_feature_file_name: mfcc_data
    raw_feature_file_name: raw_data

    # filter damaged files
    filter_damaged_files: False

    # flag for enabling randomize best onsets from find highes energy region
    rand_best_onset: True

    # if randomize best onsets set in dataset, specify spread in percent of window size
    rand_delta_percs: 0.05

    # verbose: plot infos during extraction
    verbose: False


  # my recordings dataset
  my_recordings:

    # file extension for audio files
    file_ext: '.wav'

    # number of samples
    sample_num_normal: 16000
    sample_num_mininmal: 8000

    # path to speech command dataset
    dataset_path: ignore/dataset/my_recordings/

    # shuffle wavs for dataset separation
    shuffle_wavs: False

    # extraction path
    extraction_path: ignore/dataset/_extracted/

    # paths for sets
    set_folders:
      my: my/

    # split of dataset
    split_percs: 
      my: 1.0

    # folder names
    wav_folder: wavs/
    annotation_folder: annotation/

    # plot path root
    plot_paths:
      main: _plots/
      examples_grid: _plots/grid/
      mfcc: _plots/mfcc/
      stats: _plots/stats/
      waveform: _plots/waveform/
      damaged_files: _plots/damaged_files/
      onsets: _plots/onsets/

    # enable plot of each feature extraction
    enable_plot: False

    # recreate all datasets (copy wavs to data_paths - not necessary except the dataset is changed)
    recreate: False
    clean_files: False

    # all labels
    all_labels: ['left', 'right', 'up', 'down', 'go']

    # selected labels of the whole set
    sel_labels: ['left', 'right', 'up', 'down', 'go']

    # add noise to dataset
    add_noise: False
    noise_label: _noise
    noise_data_folder: _background_noise_/

    # shift of noise window to extract noise samples [seconds]
    noise_shift_s: 0.110

    # add mixed to dataset
    add_mixed: False
    mixed_label: _mixed
    
    #version
    version_nr: 5

    # number of examples picked from dataset
    n_examples: 5

    # file name for saved feature files
    mfcc_feature_file_name: mfcc_data_my
    raw_feature_file_name: raw_data_my

    # filter damaged files
    filter_damaged_files: False

    # flag for enabling randomize best onsets from find highes energy region
    rand_best_onset: False

    # if randomize best onsets set in dataset, specify spread in percent of window size
    rand_delta_percs: 0.05

    # verbose: plot infos during extraction
    verbose: True


# --
# feature params for dataset extraction

feature_params:

  # mfcc_features or raw samples
  use_mfcc_features: True

  # sampling rate
  fs: 16000

  # window and hop size in seconds
  N_s: 0.025
  hop_s: 0.010

  # time size in seconds
  frame_size_s: 0.5

  # frame size of output features -> input to nn
  #frame_size: 32
  frame_size: 50

  # number of filter bands and cepstral coeffs for mfcc
  n_filter_bands: 32
  n_ceps_coeff: 12

  # normalized features -> [0, 1] over frames
  norm_features: True

  # old ones do not use anymore: #compute_deltas: True #compute_energy_features: True

  # stacking option
  old_stacking: False

  # use deltas as own channels
  use_channels: False

  # feature collection
  use_cepstral_features: True
  use_delta_features: False
  use_double_delta_features: False
  use_energy_features: False


# --
# machine learning settings

ml:

  # nn architecture available
  nn_architectures: {1: 'conv-trad', 2: 'conv-fstride', 3: 'adv-experimental', 4: 'conv-experimental', 5: 'conv-encoder'}

  # choose architecture
  #nn_arch: conv-experimental
  #nn_arch: conv-fstride
  #nn_arch: conv-trad
  nn_arch: conv-jim
  #nn_arch: adv-experimental
  #nn_arch: adv-jim
  #nn_arch: adv-jim-label
  #nn_arch: hyb-jim
  #nn_arch: hyb-jim-g
  #nn_arch: wavenet

  # params
  train_params:

    # training params for cnn architectures
    cnn: {'batch_size': 32, 'num_epochs': 2000, 'lr': 0.0001, 'beta': 0.9}

    # adv
    adv: {'batch_size': 32, 'num_epochs': 1000, 'lr_d': 0.0001, 'lr_g': 0.0001, 'beta_d': 0.9, 'beta_g': 0.9, 'k_update_d': -1, 'k_update_g': -1}

    # pre adv dual
    adv_dual: {'batch_size': 32, 'num_epochs': 100, 'lr_d': 0.0001, 'lr_g': 0.0001, 'beta_d': 0.9, 'beta_g': 0.9, 'k_update_d': 2, 'k_update_g': 2}

    # pre adv label train
    adv_label: {'batch_size': 32, 'num_epochs': 100, 'lr_d': 0.0001, 'lr_g': 0.0001, 'beta_d': 0.9, 'beta_g': 0.9, 'k_update_d': 2, 'k_update_g': 2}

    # hybrid net
    hyb: {'batch_size': 32, 'num_epochs': 3000, 'lr': 0.0001, 'beta': 0.9, 'lr_d': 0.00001, 'lr_g': 0.00001, 'beta_d': 0.5, 'beta_g': 0.5, 'k_update_d': 2, 'k_update_g': 3}

    # wavenet
    wave: {'batch_size': 32, 'num_epochs': 100, 'lr': 0.001, 'beta': 0.9}


  # adversarial parameters
  adv_params:

    # pre training with dual network
    dual_train: False

    # pre training with label network
    label_train: False

    # use decoder weights for further training
    use_decoder_weights: True


  # use a pre trained model at pre trained model path
  load_pre_model: False

  # saves the model as pre trained model
  save_as_pre_model: False

  # retrain existing model
  retrain: False

  # create new instance
  new_instance: True

  # number of instances
  num_instances: 1

  # logging enable
  logging_enabled: True

  # use cpu
  use_cpu: False

  # animation
  create_animation: False

  # collections
  create_collections: False

  # paths
  paths:
    log: ignore/logs/
    model: ignore/models/ 

  # folders in model path
  model_path_folders:
    conv_plots: conv_plots/
    conv_diff_plots: conv_plots/diff_plots/
    train_collections: train_collections/

  # adv pre training folder
  adv_pre_folder: adv_pre/
  #conv_folder: ../conv_coder/

  # file names
  model_file_name: model.pth
  model_pre_file_name: model_pre.pth
  params_file_name: params.npz
  metrics_file_name: metrics.npz
  info_file_name: info.txt
  score_file_name: info_score.txt


# --
# test bench

test_bench:

  # plot path
  paths:
    main_path: ignore/test_bench/
    #models_path: ignore/test_bench/test_models/
    shift_wavs: ignore/test_bench/plots/shift_wavs/
    noise_wavs: ignore/test_bench/plots/noise_wavs/

  # enable plot (wav plots -> make it slow)
  enable_plot: False

  # info prints
  enable_info_prints: False

  # test wavs
  test_wavs:
    - ignore/dataset/my_recordings/clean_records/left.wav
    - ignore/dataset/my_recordings/clean_records/right.wav
    - ignore/dataset/my_recordings/clean_records/up.wav
    - ignore/dataset/my_recordings/clean_records/down.wav
    - ignore/dataset/my_recordings/clean_records/go.wav

  # file names
  model_file_names: ['cnn_model.pth', 'g_model.pth', 'd_model.pth', 'hyb_model.pth', 'wav_model.pth']
  params_file_name: 'params.npz'

  # snrs
  snrs: [16, 13, 10, 6, 3, 0, -3, -6, -10, -13, -16]

  # shift frames by steps
  shift_frame_step: 1


# --
# classifier

classifier:

  # path to model
  model_path: 'models/conv-fstride/v3_c-5_n-2000/bs-32_it-1000_lr-1e-05/'
  #model_path: 'models/conv-encoder/v4_c-5_n-500_f-13x50/bs-32_it-1024_lr-0p0001/'

  # file names
  model_file_names: ['cnn_model.pth', 'g_model.pth', 'd_model.pth', 'hyb_model.pth', 'wav_model.pth', 'model.pth']
  params_file_name: 'params.npz'

  # verbose
  verbose: False


# --
# microphone parameters

mic_params:

  # slect specific device
  select_device: False

  # sel device id
  device: 0

  # sampling frequency of your microphone device (idealy this would be 16000, as it will be downsampled to it)
  fs_device: 48000

  # channels to be recorded
  channels: 1

  # energy threshold for onsets
  energy_thresh_db: -40.0

  # collector update size (pre frames)
  update_size: 32

  # collector post frames (after onset detection)
  frames_post: 32

  # plot of mic
  plot_path: 'ignore/mic/'

  # enable plot (set false when playing, just for debugging)
  enable_plot: False


# --
# game settings

game:

  # frames per seconds
  fps: 60

  # size of display
  screen_size: [640, 480]

  # enabled flag
  capture_enabled: False

  # capture path
  paths:
    capture_path: ignore/capture/
    frame_path: ignore/capture/frames/

  # user settings file
  user_setting_file: user_settings_game.yaml