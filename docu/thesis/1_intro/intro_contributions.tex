% --
% contributions

\section{Contributions}
\thesisStateNew
Key Word Spotting (KWS) incorporated in video games require fast response times, therefore it was necessary to reduce the examples from the used speech commands dataset \cite{Warden2018} from \SI{1}{\second} to at least \SI{500}{\milli\second}.
This reduction was done by determining the onset of the highest energy region within the speech signal.
By using the first cepstral coefficient of Mel Frequency Cepstral Coefficients (MFCC) it was possible to use a very efficient onset method.
The focus on the used neural networks were Convolutional Neural Network (CNN) models with low computational footprints, such as shown in \cite{Sainath2015}.
Besides low computational footprint, the depth of layers is hold to a minimum, so that it is still possible to obtain information about the trained feature maps from the convolutional layers of CNN networks.
The input features of CNN models were MFCC.
The amount of MFCC cepstral coefficients was evaluated with either 12 or 32 cepstral coefficients and showed that no accuracy improvements were achieved with 32 cepstral coefficients compared to 12.
The enhancement of MFCC to 39-feature vectors with 12 cepstral coefficients was evaluated likewise and showed only small improvements of accuracies, but no significant ones, which lead to the decision to use less feature vectors and continue the experiments with 12 MFCC coefficients without enhancement.
A frame-based normalization was introduced and performed on MFCCs to suite them better for visualization and use them for Generative Adversarial Networks (GAN) training.
Evaluation of the frame-based normalization was done in terms of accuracy, shift and noise invariance on conventional CNN models.
Frame-based normalization showed significant worse accuracies (about 5 to \SI{10}{\percent}) and took a bit longer for training, but improved the noise invariance properties in many experiments.
The following experiments were done with 12 cepstral coefficients and frame-based normalization.

Another large evaluation topic was the application of Generative Adversarial Networks (GAN) on the MFCC extracted speech commands. 
With frame-based normalization the Generator (G) network was able to learn faster to create convincing fakes to fool the Discriminator (D) network.
However it was found, when G and D are trained for too long, an equilibrium state where both generate random outputs of either fake images or decisions might happen.
To solve this problem, a second loss term for G was added, that measures the similarity of the generated samples to the input data with the cosine distance.
This helped to generate better fakes and did not lead into noisy equilibrium states anymore.

From the adversarial training of GAN networks, it was examined how their obtained weights through training can contribute in the performance of an equivalent CNN models, with same convolutional layer structures.
The transfer of the obtained weights (transfer learning) from either D or G were done, to initialize the weights of a separate training instance of an equivalent CNN model for the KWS task.
With this approach it was possible to significantly increase the accuracy performance of about \SI{3}{\percent} by using weights from G.
It showed that the obtained weights of G from an adversarial training can be very valuable if frame-based normalization was applied.

A completely different approach for KWS was the evaluation of a Wavenet \cite{Oord2016} model for classification.
However with the hope that without feature extraction, less computations are necessary in the application of an online system for video games, turned out to be extremely wrong.
Wavenets need a huge amount of operations by processing each sample from the audio files of the dataset, through dilated convolutional filters over many layers.
Further the performances turned out to be very bad.
Nevertheless this model with an extension for class predictions was evaluated and results are provided for future research.

A complete deployment of a KWS game was done, with an online system capturing the microphone input stream and a classification to speech commands for rendering actions in the the game.