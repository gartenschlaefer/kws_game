% --
% training details

\section{Implementation and Training Details}\label{sec:exp_details}
\thesisStateNotReady
In this sections, the implementation und parameters for training are described in more detail.

% --
% implementation notes

\subsection{Implementation notes}\label{sec:exp_details_implementation}
The programming code for this thesis was entirely done in \texttt{Python} with version $>3.8$ evaluated on a linux system.
This might be important if one tries to run the python code on a windows machine, it was not tested for it and could yield in errors (especially regarding paths variables).
The training and implementation of all used neural networks are done with the \texttt{Pytorch} \cite{Pytorch} framework with version $1.7.0$. 
Usually it should not be a problem if a newer version of \texttt{Pytorch} are applied, during the work on the thesis the version changed to $1.9.0$ with no problems.
The feature extraction of Mel Frequency Cepstral Coefficients (MFCC) self implemented, but using efficients functions for transforms, such as the Short Time Fourier Transform (STFT) or Discrete Cosine Transform (DCT), with packages from \texttt{scipy}.
Matrix computations were usually done with the well known package \texttt{numpy}.
Several other \texttt{Python} packages were used within the project, but are not named explicitly, they can be looked up in the open source repository of the project.


% --
% training details

\subsection{Neural Network Training Details}\label{sec:exp_details_training}
The training details of the used neural networks can be split into following parameters:
\begin{enumerate}
  \item Features extraction parameters
  \item Dataset parameters
  \item Feature selection
  \item Transfer Learning parameters
  \item Training parameters
\end{enumerate}
The feature extraction parameters provide information about how the MFCC feautes were extracted.
Note that no
During the feature selection experiments the parameters for cepstral coefficients with enhancements are varying normalization.
If not other stated, the feature extraction parameters in \rtab{exp_details_params_feature} are used.
\input{./5_exp/tables/tab_exp_details_params_feature}
The dataset parameters are the selected labels and the number of examples per labels.
The selected labels are either the 12 labels for comparison to the benchmark networks described in \rsec{prev_kws_benchmark} or 7 labels used for the deployed KWS Game are listed as well as the number of examples per label in \rtab{exp_details_params_dataset}.
\input{./5_exp/tables/tab_exp_details_params_dataset}
%The Abbreviation regarding dataset parameters and feature selection were already listed in \rtab{exp_dataset_abbr}.
%The feature selection is the information about what input feature groups are used in the training, e.g. use cepstral coefficients only, or add delta and energy features, their references are shown in \rtab{dataset_feature_groups}.
The transfer learning parameters describe the training details of the adversarial networks and what
For instance it describes if the weights are used from the discriminator or generator network or how much epochs were used for the adversarial training, etc.
%The Abbreviations for training parameters can be specified as listed in \rtab{exp_details_adv}
%\input{./5_exp/tables/tab_exp_details_adv.tex}

The training parameters are classical parameters for neural network training, such as learning rate, number of epochs, etc.
%Their selection and references are listed in \rtab{exp_details_train_params}
%\input{./5_exp/tables/tab_exp_details_train_params.tex}

