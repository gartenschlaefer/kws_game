% --
% training details

\section{Implementation and Experiment Details}\label{sec:exp_details}
\thesisStateReady
The implementation describes the used software tools for the experiments on the neural networks, such as the programming language and packages for the source code.
The training details provide commonly used sets of hyperparameters applied to train neural networks.
Note that the training details can vary between different experiments and models and that the listing provide merely an overview of all available parameters to choose from with recommendations of parameters for the speech command dataset.
If parameters are varying in some experiments, they are usually noted, otherwise the parameters listed were used.
The evaluation details of the models is described separately and evaluates the trained models upon accuracy and noise and shift invariance.


% --
% implementation notes

\subsection{Implementation Notes}\label{sec:exp_details_implementation}
The source code for this thesis was entirely written in \texttt{Python} with version $>3.8$ evaluated on a Linux operating system and is open source available at \cite{KWSGame}.
The operating system might be important if someone tries to run the python code on a \enquote{Windows} machine, where unexpected errors might occur (especially regarding path variables).
Also the project does not download the speech command dataset by its own and a path to the dataset has to be specified in the \texttt{config.yaml} file of the project.
More on information about how to run the project is described in the \texttt{README.txt} file.
The training and implementation of all used neural networks were done with the \texttt{Pytorch} \cite{Pytorch} framework of version $1.7.0$. 
Usually it should not be a problem if a newer version of \texttt{Pytorch} is used, during the work on the thesis the version changed to $1.9.0$ without any version depending problems.
The feature extraction of MFCCs was self implemented, but use already existing and efficient code for transforms, such as the STFT or DCT, with packages from \texttt{Scipy}.
All matrix-vector computations were done with the well known package \texttt{Numpy} or with \texttt{Pytorch}.
Several other \texttt{Python} packages were used within the project, but are not named explicitly, they can be looked up in the open source repository of the project, if requested.


% --
% training details

\subsection{Neural Network Training Details}\label{sec:exp_details_training}
The training details of the used neural networks described in \rsec{nn_arch} can be split into following parameters:
\begin{enumerate}
  \item Feature extraction parameters
  \item Dataset parameters
  \item Training hyperparameters
  \item Pre-Training details
\end{enumerate}
The feature extraction parameters provide information about how the MFCC features were extracted in detail.
The dataset parameters are the selected labels and the number of examples per labels for training.
With the training hyperparameters, the neural network training is specified, such as the learning rate or batch size.
The pre-training details are describing a separate training of GANs, to use the obtained weights for transfer learning on an equivalent CNNs.
Therefore the pre-training details are similar to the training hyperparameters and describe the training details of both the Generator (G) and Discriminator (D) network of the GANs.


% --
% feature

\subsubsection{Feature extraction parameters}
During the feature selection experiments in \rsec{exp_fs}, the feature extraction parameters for cepstral coefficients with enhancements are varying.
If not other stated, the feature extraction parameters in \rtab{exp_details_params_feature} are used.
\input{./5_exp/tables/tab_exp_details_params_feature}


% --
% dataset

\subsubsection{Dataset parameters}
The selected labels for training are either the 12 labels (L12) for comparison to the benchmark networks described in \rsec{prev_kws_benchmark} or 7 labels (L7) used for the deployed KWS game are listed as well as the number of examples per label in \rtab{exp_details_params_dataset}.
\input{./5_exp/tables/tab_exp_details_params_dataset}
However in all experiments the L12 labels are used, so that a comparison to previous work is possible.
The maximal number of examples per label for training is chosen by the minimum examples per selected label for each label and each set.
This is provided by the validation set of \enquote{go} with \{train: 2948, test: 425, validation: 350 \} shown in \rtab{exp_dataset_all_labels}, with 350 examples per label in the validation set, considering a \SI{10}{\percent} split of both test and validation set.
This gives a maximal amount of 3500 examples per label to represent the whole dataset.
This is important, because the number of examples per label should not be chosen to higher values than 3500 for training, otherwise the same amount of examples per label is not given.


% --
% training hyperparameters

\subsubsection{Training hyperparameters}
The hyperparameters for training the used CNNs models, described in \rsec{nn_arch}, are shown in \rtab{exp_details_params_train}.
\input{./5_exp/tables/tab_exp_details_params_train}
From the following experiments it can be observed that epochs of 2000 yield into small overfitting effects regarding certain models, but it was important to examine when these effects are starting.
The batch size of 32 is selected to a low number, because it worked well and the amount of classes were at maximum 12 (L12).
%Note that the batch size influences the selection of the learning rate for updating the parameters of the neural network models.

The hyperparameters for the Wavenet model are described in the corresponding experiment section.


% --
% training parameters

\subsubsection{Pre-Training details}
The pre-training parameters describe the training of the GANs, with their models presented in \rsec{nn_arch_adv} and \rsec{nn_adv}.
The hyperparameters shown in \rtab{exp_details_params_pre_train} are the same as for usual model training, but the Discriminator (D) and Generator (G) network can have different values.
\input{./5_exp/tables/tab_exp_details_params_pre_train}
The selection of the epochs is important as it was already pointed out in \rsec{nn_adv}.


% --
% evaluation details

\subsection{Evaluation details}\label{sec:exp_details_tb}
The main evaluation score of the trained models is the computation of the accuracy on the test sets.
The accuracy is simply obtained by counting all correct classifications and dividing it by the number of classified samples $n$.
A score function $c(\hat{y}_i, y_i)$ for the accuracy can be defined as:
\begin{equation}
  c(\hat{y}_i, y_i) = 
  \begin{cases}
    1, & \text{if } \hat{y}_i = y_i\\
    0, & \text{otherwise} 
  \end{cases}
\end{equation}
where $\hat{y}_i \in \mathcal{L} = \{0, 1, \dots, L\} $ is the predicted label and $y_i \in \mathcal{L}$ the actual label of the sample $i$ with a total number of class labels $L$.
The accuracy $a \in [0, 1]$ can therefore be written as:
\begin{equation}
  a = \frac{1}{n} \sum_{i=0}^n c(\hat{y}_i, y_i)
\end{equation}
Another more unconventional evaluation technique used, is the evaluation on noise and shift invariance.
For this one sample from each class label from the self recorded files of the \enquote{my dataset} is used as test signals.
The length of those audio files is cut, such that by applying a fixed input frame of \SI{500}{\milli\second}, both end positions consists of at least the half of the audio file information, which is especially important for the shift invariance.
The evaluation results are plotted in figures of correct classification upon shift and noise level changes.
Note that the noise and shift invariance are tested on only 5 test signals and therefore they are not a reliable measure for the trained models, but it is interesting to see how different models perform upon these tests.
In the following the shift and noise invariance tests are explained in more detail.


% --
% shift invariance

\subsubsection{Shift invariance}
Shift invariance is a very important property for speech recognition, for instance the classification of a waveform should still be the same regardless of little shifts in time, as long there is enough and valuable information present that is necessary for a correct classification.
However the restricted frame size of \SI{500}{\milli\second} might increase the difficulty in this task, not all relevant information of the speech signal can be captured by the analytic window, like the \enquote{t} in \enquote{left} or \enquote{right} is often missed.
An example of the application of the shift invariance test is shown in \rfig{exp_details_tb_shift_left} with a beginning, middle and end frame shift.
\begin{figure}[!ht]
  \centering
    \subfigure[frame shift 0]{\includegraphics[width=0.45\textwidth]{./5_exp/figs/exp_details_tb_shift_left_frame0}}
    \subfigure[frame shift 30]{\includegraphics[width=0.45\textwidth]{./5_exp/figs/exp_details_tb_shift_left_frame30}}
    \subfigure[frame shift 59]{\includegraphics[width=0.45\textwidth]{./5_exp/figs/exp_details_tb_shift_left_frame59}}
  \caption{Shifting a self recorded example of \enquote{left} with certain amounts of frame shifts and provided classification results in the title annotations.}
  \label{fig:exp_details_tb_shift_left}
\end{figure}
\FloatBarrier
\noindent
The figures in this section present a correct classification with a colored pixel and an incorrect with a white pixel.
One example of a shift invariance test is shown in \rfig{exp_details_tb_shift}.
\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.65\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_shift_conv-jim_mfcc12_norm0}
  \caption{Shift invariance test example selected from the trained models in the experiments.}
  \label{fig:exp_details_tb_shift}
\end{figure}
\FloatBarrier
\noindent
The purpose of the shift invariance test is not to achieve a full classification score upon each test example, because this is hardly possible if not all of a key words information is captured within the shifted frame, but to provide consecutive correct classifications within a certain region.
Holes in this region are not a good indicator for the trained model.
If one example could not be classified at all, it does not necessarily mean that the trained model is bad, but that this special example is not recognized with this specific model.
A good model has a wide region of correct classifications with no holes in it.


% --
% noise invariance

\subsubsection{Noise invariance}
The classification of speech signals often requires noise invariance, because a significant amount of noise can be added from the use of bad microphones or recording set ups and therefore might disturb the classification accuracy.
To create a test upon noise invariance, artificial normal noise was added to the test signal $\bm{x} \in \R^n$ by
\begin{equation}
  \bm{\tilde{x}} = \bm{x} + \bm{v}, \quad \bm{v} \sim \mathcal{N}(\mu, \sigma)
\end{equation}
where $\bm{v} \in \R^n$ is the additive normal noise sampled from $\mathcal{N}(\mu, \sigma)$ with mean $\mu = 0$ and standard deviation $\sigma$.
The additive noise is parametrized with the standard deviation $\sigma$ to create a certain Signal to Noise Ratios (SNR) $S$.
The standard deviation can therefore be obtained through $S$ with:
\begin{equation}
  \sigma = \sqrt{\frac{\frac{1}{n}\bm{x}^T \bm{x}}{10^{\frac{S}{10}}}}
\end{equation}
where $S$ is the SNR in decibel (dB). 
A SNR level of zero means there is equal energy of the added noise $\bm{v}$ and the test signal $\bm{x}$, therefore the resulting signal is already strong disturbed with noise.
An example of the noise invariance test with a low, middle and high SNR value is shown in \rfig{exp_details_tb_noise_left}.
\begin{figure}[!ht]
  \centering
    \subfigure[\SI{16}{\dB}]{\includegraphics[width=0.45\textwidth]{./5_exp/figs/exp_details_tb_noise_left_snr16}}
    \subfigure[\SI{0}{\dB}]{\includegraphics[width=0.45\textwidth]{./5_exp/figs/exp_details_tb_noise_left_snr0}}
    \subfigure[\SI{-16}{\dB}]{\includegraphics[width=0.45\textwidth]{./5_exp/figs/exp_details_tb_noise_left_snr-16}}
  \caption{Adding noise to a self recorded example of \enquote{left} with certain amounts of SNR values and provided classification results in the title annotations.}
  \label{fig:exp_details_tb_noise_left}
\end{figure}
\FloatBarrier
\noindent
In the plots for the experiments, the added noise is indicated in the x-axis with the SNR value.
\rfig{exp_details_tb_noise} shows a example of a noise invariance test.
\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.35\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_noise_conv-jim_mfcc12_norm0}
  \caption{Noise invariance test example selected from the trained models in the experiments.}
  \label{fig:exp_details_tb_noise}
\end{figure}
\FloatBarrier
\noindent
The same criteria as described in the shift invariance also applies to the noise invariance, but the region of consecutive correct classifications should start from low noise levels to high noise levels.