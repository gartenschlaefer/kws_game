% --
% feature selection

\section{Experiments on MFCC Feature Selection}\label{sec:exp_fs}
Feature selection is a very important step prior to neural network training.
It reduces the input features and therefore also the computations in the classification model.
Unfortunately, it is not always clear which feature are contributing in the enhancement of classification scores and which do not or even worsen them.
In this section, only MFCCs and their enhancements, as described in \rsec{signal_mfcc}, are the focus in the experiments.
A feature selection for raw audio samples, such as used in the Wavenet architecture, would not make any sense because each sample is a strongly uncorrelated feature itself.
Another important aspect in the feature selection experiments, is the evaluation of the proposed frame-based normalization \req{signal_mfcc_norm} originally intended to improve the visualization of MFCCs and making the Generator network of GANs easier and faster to train.
However, frame-based normalization might be critical because this normalization applies only on the frame (time) dimension and disregards the cepstral dimension.

Two experiments are performed on the MFCC feature selection and evaluate on the one hand the impact on the amount of cepstral coefficients and on the other hand the impact on the enhancements of MFCCs.
For saving training time and computations, those experiments were performed on 500 examples per label, as noted in \rsec{exp_details_training}.
Further, both experiments use a fixed number of 32 filter bands.
Five consecutive training instances are performed on the same model and parameter set in order to provide basic statistics for the evaluation scores.
The statistics present a mean value and the standard deviation (square root of the variance) of the accuracy scores from all training instances.
The experiments do not apply any early stopping mechanism and therefore use the model parameters from the last epoch for evaluation.
Note that the experiments in this sections are not meant for comparison to the benchmark networks in \rsec{prev_kws_benchmark} because not the whole dataset was used.


% --
% cepstral

\subsection{Impact on the Amount of Cepstral Coefficients}
This experiment evaluates the accuracies of different CNN models using a number of either 12 or 32 cepstral coefficients from the extracted MFCCs.
Note that a number of 12 coefficients with enhancements is commonly applied in many papers.
The experiments were performed once with and once without frame-based normalization.
Further, the trained models were evaluated regarding their noise and shift invariance, as described in \rsec{exp_details_tb}.
The experiment uses the standard set of training hyperparameters from \rtab{exp_details_params_train}.
\rtab{exp_fs_cepstral_l12} shows the experiment with 2000 training epochs performed on all three CNN models.
Note that the normalization is active if the table lists a \enquote{1} in the \enquote{Norm.} column, otherwise the normalization is not applied and indicated by a \enquote{0}.
\input{./5_exp/tables/tab_exp_fs_cepstral_l12.tex}
\rfig{exp_fs_cepstral_acc} shows the accuracies on the validation set of the best performing training instances for each model, where the accuracies are smoothed by a striding average filter with a length of 10 epochs for better visualization.
\begin{figure}[!ht]
  \centering
  \subfigure[conv-trad]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_cepstral_acc_conv-trad.png}}
  \quad
  \subfigure[conv-fstride]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_cepstral_acc_conv-fstride.png}}
  \subfigure[conv-jim]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_cepstral_acc_conv-jim.png}}
  \caption{Accuracies on the validation set of all three CNN models of their best training instance with different amounts of cepstral coefficients and with and without frame-based normalization. The results were smoothed with a 10 epoch average filter.}
  \label{fig:exp_fs_cepstral_acc}
\end{figure}
\FloatBarrier
\noindent
From the provided results, it can be observed that the use of 32 cepstral coefficients does not improve the accuracies compared to the 12 coefficients.
Also the overfitting effects are more prominent when 32 coefficients are applied.
Moreover, they show that frame-based normalization usually achieves a lower accuracy and requires more epochs until convergence is reached.

In the following, the shift and noise invariance of each model is evaluated.
The noise and shift invariance tests of the \texttt{conv-trad} model are shown in \rfig{exp_fs_cepstral_tb_noise_conv-trad} and \rfig{exp_fs_cepstral_tb_shift_conv-trad}, respectively.
\begin{figure}[!ht]
  \centering
  \subfigure[\#MFCC: 12, Norm.: 0]{\includegraphics[width=0.35\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_noise_conv-trad_mfcc12_norm0.png}}
  \qquad
  \subfigure[\#MFCC: 12, Norm.: 1]{\includegraphics[width=0.35\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_noise_conv-trad_mfcc12_norm1.png}}
  \subfigure[\#MFCC: 32, Norm.: 0]{\includegraphics[width=0.35\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_noise_conv-trad_mfcc32_norm0.png}}
  \qquad
  \subfigure[\#MFCC: 32, Norm.: 1]{\includegraphics[width=0.35\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_noise_conv-trad_mfcc32_norm1.png}}
  \caption{Noise invariance of the \texttt{conv-trad} model with different amounts of cepstral coefficients and with and without frame-based normalization.}
  \label{fig:exp_fs_cepstral_tb_noise_conv-trad}
\end{figure}
\FloatBarrier
\noindent
\begin{figure}[!ht]
  \centering
  \subfigure[\#MFCC: 12, Norm.: 0]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_shift_conv-trad_mfcc12_norm0.png}}
  \quad
  \subfigure[\#MFCC: 12, Norm.: 1]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_shift_conv-trad_mfcc12_norm1.png}}
  \subfigure[\#MFCC: 32, Norm.: 0]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_shift_conv-trad_mfcc32_norm0.png}}
  \quad
  \subfigure[\#MFCC: 32, Norm.: 1]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_shift_conv-trad_mfcc32_norm1.png}}
  \caption{Shift invariance of the \texttt{conv-trad} model with different amounts of cepstral coefficients and with and without frame-based normalization.}
  \label{fig:exp_fs_cepstral_tb_shift_conv-trad}
\end{figure}
\FloatBarrier
\noindent
The noise and shift invariance tests of the \texttt{conv-fstride} model are shown in \rfig{exp_fs_cepstral_tb_noise_conv-fstride} and \rfig{exp_fs_cepstral_tb_shift_conv-fstride}, respectively.
\begin{figure}[!ht]
  \centering
  \subfigure[\#MFCC: 12, Norm.: 0]{\includegraphics[width=0.35\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_noise_conv-fstride_mfcc12_norm0.png}}
  \subfigure[\#MFCC: 12, Norm.: 1]{\includegraphics[width=0.35\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_noise_conv-fstride_mfcc12_norm1.png}}
  \subfigure[\#MFCC: 32, Norm.: 0]{\includegraphics[width=0.35\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_noise_conv-fstride_mfcc32_norm0.png}}
  \subfigure[\#MFCC: 32, Norm.: 1]{\includegraphics[width=0.35\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_noise_conv-fstride_mfcc32_norm1.png}}
  \caption{Noise invariance of the \texttt{conv-fstride} model with different amounts of cepstral coefficients and with and without frame-based normalization.}
  \label{fig:exp_fs_cepstral_tb_noise_conv-fstride}
\end{figure}
\FloatBarrier
\noindent
\begin{figure}[!ht]
  \centering
  \subfigure[\#MFCC: 12, Norm.: 0]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_shift_conv-fstride_mfcc12_norm0.png}}
  \quad
  \subfigure[\#MFCC: 12, Norm.: 1]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_shift_conv-fstride_mfcc12_norm1.png}}
  \subfigure[\#MFCC: 32, Norm.: 0]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_shift_conv-fstride_mfcc32_norm0.png}}
  \quad
  \subfigure[\#MFCC: 32, Norm.: 1]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_shift_conv-fstride_mfcc32_norm1.png}}
  \caption{Shift invariance of the \texttt{conv-fstride} model with different amounts of cepstral coefficients and with and without frame-based normalization.}
  \label{fig:exp_fs_cepstral_tb_shift_conv-fstride}
\end{figure}
\FloatBarrier
\noindent
The noise and shift invariance tests of the \texttt{conv-jim} model are shown in \rfig{exp_fs_cepstral_tb_noise_conv-jim} and \rfig{exp_fs_cepstral_tb_shift_conv-jim}, respectively.
\begin{figure}[!ht]
  \centering
  \subfigure[\#MFCC: 12, Norm.: 0]{\includegraphics[width=0.35\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_noise_conv-jim_mfcc12_norm0.png}}
  \qquad
  \subfigure[\#MFCC: 12, Norm.: 1]{\includegraphics[width=0.35\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_noise_conv-jim_mfcc12_norm1.png}}
  \subfigure[\#MFCC: 32, Norm.: 0]{\includegraphics[width=0.35\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_noise_conv-jim_mfcc32_norm0.png}}
  \qquad
  \subfigure[\#MFCC: 32, Norm.: 1]{\includegraphics[width=0.35\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_noise_conv-jim_mfcc32_norm1.png}}
  \caption{Noise invariance of the \texttt{conv-jim} model with different amounts of cepstral coefficients and with and without frame-based normalization.}
  \label{fig:exp_fs_cepstral_tb_noise_conv-jim}
\end{figure}
\FloatBarrier
\noindent
\begin{figure}[!ht]
  \centering
  \subfigure[\#MFCC: 12, Norm.: 0]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_shift_conv-jim_mfcc12_norm0.png}}
  \quad
  \subfigure[\#MFCC: 12, Norm.: 1]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_shift_conv-jim_mfcc12_norm1.png}}
  \subfigure[\#MFCC: 32, Norm.: 0]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_shift_conv-jim_mfcc32_norm0.png}}
  \quad
  \subfigure[\#MFCC: 32, Norm.: 1]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_cepstral_tb_shift_conv-jim_mfcc32_norm1.png}}
  \caption{Shift invariance of the \texttt{conv-jim} model with different amounts of cepstral coefficients and with and without frame-based normalization.}
  \label{fig:exp_fs_cepstral_tb_shift_conv-jim}
\end{figure}
\FloatBarrier
\noindent
While the results of the invariance tests do not allow a general conclusion, following patterns can be observed regardless:
The frame-based normalization does certainly increase the invariance in noise, which is logical because the model has to concentrate more on the learning of patterns from the individual keywords and is less prone to overfitting.
The \texttt{conv-fstride} model does unexpectedly well upon the shift invariance test, even though its strides perform only on the frequency axis.
Although it usually does not achieve that good shift invariance results compared to the other models.
The \texttt{conv-trad} model performs best on all tests but also requires a higher computational footprint so that the preferred model is the \texttt{conv-jim} model.
The usage of 32 MFCC coefficients does not improve the invariance against shift or noise and very often worsens the results.


% --
% enhancements

\subsection{Impact on the Enhancements of MFCCs}\label{sec:exp_fs_mfcc}
This experiment fixes the amount of cepstral coefficients (c) to 12 and enhances those with deltas (d), double deltas (dd), and energy vectors (e), as described in \rsec{signal_mfcc_enhancement}.
\rtab{exp_fs_mfcc_l12} lists the results of the experiments with applied frame-based normalization, 2000 training epochs, and the hyperparameter set for CNN models in \rtab{exp_details_params_train}.
Note that a \enquote{1} in the columns of the cepstral coefficients and enhancements means it is included in the input features, otherwise it is denoted as \enquote{0}.
\input{./5_exp/tables/tab_exp_fs_mfcc_l12.tex}
The best two feature enhancements were the full MFCC-39 features (c1d1dd1e1) and the (c1d1dd0e1) features without double deltas.
Further, they were selected in order to examine the accuracy on the validation set during training, which is shown in \rfig{exp_fs_mfcc_tb_acc_conv-jim}.
The noise and shift invariance tests are provided in \rfig{exp_fs_mfcc_tb_noise_conv-jim} and \rfig{exp_fs_mfcc_tb_shift_conv-jim}, respectively.
\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_mfcc_acc_conv-jim.png}
  \caption{Accuracies of the \texttt{conv-jim} model with different feature enhancements and frame-based normalization.}
  \label{fig:exp_fs_mfcc_tb_acc_conv-jim}
\end{figure}
\FloatBarrier
\noindent
\begin{figure}[!ht]
  \centering
  \subfigure[c1d1dd1e1]{\includegraphics[width=0.35\textwidth]{./5_exp/figs/exp_fs_mfcc_tb_noise_conv-jim_c1d1d1e1.png}}
  \qquad
  \subfigure[c1d1dd0e1]{\includegraphics[width=0.35\textwidth]{./5_exp/figs/exp_fs_mfcc_tb_noise_conv-jim_c1d1d0e1.png}}
  \caption{Noise invariance of the \texttt{conv-jim} model with different feature enhancements and frame-based normalization.}
  \label{fig:exp_fs_mfcc_tb_noise_conv-jim}
\end{figure}
\FloatBarrier
\noindent
\begin{figure}[!ht]
  \centering
  \subfigure[c1d1dd1e1]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_mfcc_tb_shift_conv-jim_c1d1d1e1.png}}
  \quad
  \subfigure[c1d1dd0e1]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_fs_mfcc_tb_shift_conv-jim_c1d1d0e1.png}}
  \caption{Shift invariance of the \texttt{conv-jim} model with different feature enhancements and frame-based normalization.}
  \label{fig:exp_fs_mfcc_tb_shift_conv-jim}
\end{figure}
\FloatBarrier
\noindent
The experiments conclude that the enhancements of the MFCC features can improve the classification results significantly.
However, they also increases the amount of computations for each model.