% --
% Experiments on whole dataset

\section{Experiments on the whole Dataset}\label{sec:exp_final}
The final experiments are performed on the whole dataset with 3500 examples per labels and are therefore used for comparison to the benchmark models listed in \rsec{prev_kws_benchmark}.
All CNN architectures were evaluated with 12 MFCC coefficients and with and without frame-based normalization.
A single run with 2000 training epochs was performed for all experiments in order to reduce computational effort.
The evaluation on the adversarial pre-training, as described in \rsec{exp_adv}, was done for the \texttt{conv-jim} model in a separate run.
\rtab{exp_final_l12} shows the results of the experiments.
\input{./5_exp/tables/tab_exp_final_l12.tex}
Note that some of the models suffer strongly from overfitting effects, especially the \texttt{conv-trad} model without frame-based normalization, as shown in \rfig{exp_final_loss_conv-trad}.
It is therefore useful to apply an early stopping technique for better generalization that obtains the model parameters at the best performing training epoch evaluated on the validation set.
\begin{figure}[!ht]
  \centering
  \subfigure[Norm.: 0]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_final_loss_norm0_conv-trad.png}}
  \quad
  \subfigure[Norm.: 1]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_final_loss_norm1_conv-trad.png}}
  \caption{Training loss of the \texttt{conv-trad} model showing overfitting effects on the whole dataset.}
  \label{fig:exp_final_loss_conv-trad}
\end{figure}
\FloatBarrier
\noindent
The training of models with frame-based normalization has usually fewer problems with overfitting effects compared to the ones without.
\rfig{exp_final_acc} shows the classification accuracies on the validation set of all models with and without frame-based normalization.
\begin{figure}[!ht]
  \centering
  \subfigure[Norm.: 0]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_final_acc_norm0.png}}
  \quad
  \subfigure[Norm.: 1]{\includegraphics[width=0.48\textwidth]{./5_exp/figs/exp_final_acc_norm1.png}}
  \caption{Classification accuracies of the training of all models with and without frame-based normalization performed on the whole dataset and averaged over 10 epochs for better visualization.}
  \label{fig:exp_final_acc}
\end{figure}
\FloatBarrier
\noindent
Note that the classification accuracies had been smoothed over the epochs, otherwise larger spikes would have been visible.
If the recognition accuracy deflates or is very spiky over the training epochs, then an early stopping mechanism is strongly recommended.
For instance, the \texttt{conv-trad} without frame-based normalization would have reached a higher classification accuracy on the test set, if an early stopping mechanism had been applied.

There is a large gap between the evaluated models and the benchmark models.
With \SI{84.62}{\percent} the \texttt{conv-jim} model with adversarial pre-training performs about \SI{10}{\percent} worse than the benchmark model (DS-CNN-S \cite{Zhang2017HelloEdge}) with \SI{94.4}{\percent}.
Although it has to be considered that the amount of operations for the \texttt{conv-jim} model is about 6 times lower than the DS-CNN-S and that not the whole audio file of \SI{1}{\second} was processed but a shorter time interval of \SI{500}{\milli\second}.
With this in mind, the results do not look that poor.
To observe the problems in classification, a confusion matrix from the \texttt{conv-jim} model with adversarial label train on the Generator weights is shown in \rfig{exp_final_confusion}.
\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.65\textwidth]{./5_exp/figs/exp_final_confusion.png}
  \caption{Confusion matrix of the \texttt{conv-jim} model pre-trained with adversarial label train of 100 epochs using the Generator weights and 2000 training epochs applied with frame-based normalization.}
  \label{fig:exp_final_confusion}
\end{figure}
\FloatBarrier
\noindent
From the confusion matrix, it can be observed that most classifications were correct and misconceptions usually happened at similar words with the same phoneme structure like \enquote{go} and \enquote{no}.

\rsec{appendix_weights} visualizes the weights of the first convolutional layers of the trained models.
All in all, the obtained scores should be sufficient for a video game application.