% --
% Neural Network Architectures

\section{Neural Network Architectures}\label{sec:nn_arch}
\thesisStateNotReady
All neural network architectures evaluated within this thesis are presented here.
The fundamental architectures were:
\begin{enumerate}
	\item Convolutional Neural Networks (CNN)
	\item Generative Adversarial Neural Networks (GAN)
	\item Wavenets
\end{enumerate}
%The term convolutional neural network here consists of all architectures consisting of at least one convolutional layer and the intention to simply classify each speech commands from each other. 
%Therefore the output of a convolutional net is of size of the number of individual speech commands and usually has some kind of probability distribution or energy equivalence.
CNNs were used for the classification of MFCC features and are therefore the main architecture within this thesis.
Generative models, such as GANs, are always worth to examine.
In this thesis, GANs were applied to evaluate network designs and their capability to generative convincing fakes and to use the trained feature maps in the convolutional layers for classifier networks as pre-trained weights.
Wavenets are compared to CNNs a completely different approach and use even raw audio samples as inputs.
Therefore for an online system, no MFCC features have to be calculated.
The saving of computations is evaluated as well as the performance compared to the CNN approach.

% --
% CNNs

\subsection{Convolutional Neural Networks}\label{sec:nn_arch_cnn}
Three different CNN designs were evaluated, with the focus of the striding properties and therefore also the sizes of convolutional filters.
For one model the kernel size has the length of the frame (time) dimension of the input features and is therefore striding only in the MFCC (frequency) dimension.
The same holds for another model, but so that the kernel has the size of the feature dimension and therefore strides only in the frame dimension.
Also one traditional model is used, that does the strides as usual in both dimensions.
The naming of those models is as following:
\begin{itemize}
	\item \enquote{\texttt{conv-trad}}: from \cite{Sainath2015} a traditional CNN network, striding in both dimensions.
	\item \enquote{\texttt{conv-fstride4}}: from \cite{Sainath2015}, striding only in frequency dimension.
	\item \enquote{\texttt{conv-jim}}: self designed model, striding only in frame dimension.
\end{itemize}
The naming of the \texttt{conv-trad} and \texttt{conv-fstride4} comes from their original papers, the self defined network \texttt{conv-jim} was named bluntly after the astronaut avatar shown inside this thesis very often.
The network architecture of the traditional network (\texttt{conv-trad}) is shown in \rfig{nn_arch_cnn_trad}.
% conv-trad
\begin{figure}[!ht]
  \centering
    \includegraphics[height=0.2\textwidth]{./4_nn/figs/nn_arch_cnn_trad.eps}
  \caption{Traditional CNN network design from \cite{Sainath2015} named \texttt{conv-trad}.}
  \label{fig:nn_arch_cnn_trad}
\end{figure}
\FloatBarrier
\noindent
The \texttt{conv-trad} network consists of 2 convolutional layers and one max pooling layer in between.
The architecture was adapted from \cite{Sainath2015} as a baseline network and modified a bit in the kernel sizes, so that also reduced input features, for instance 12 MFCCs instead of 39 MFCC plus deltas and energies, can be computed with the same model.
The length of 20 frames in the first convolutional layer is reasonable and corresponse approximately to the length of a vowel sound.
Note that the \enquote{Flatten} layer simply flattens the output tensor of the last convolutional layers to 1-dimension, so that fully conected layers can be appended.
Dropout was used in the first two FC layers.
The last FC layer has $L$ nodes corresponding to $L$ output class labels, depending on the amount of chosen key words in the vocabulary.
Assuming that the input will be of shape $x = (1 \times 12 \times 50)$ this will give following dimensions and operations as listed in \rtab{nn_arch_cnn_trad}.
\input{./4_nn/tables/tab_nn_arch_cnn_trad.tex}

The \texttt{conv-fstride4} has the kernel size adapted to the input frame size and is therefore striding only in the frequency dimension.
The kernel heigth of 8 with vertical stride of 4 creates only two dimensions in the vertical direction for an input size of $12 \times 50$, which is very energy efficient. 
The model is shown in \rfig{nn_arch_cnn_fstride} and its footprint is listed in \rtab{nn_arch_cnn_fstride4}
\begin{figure}[!ht]
  \centering
    \includegraphics[height=0.2\textwidth]{./4_nn/figs/nn_arch_cnn_fstride.eps}
  \caption{Frequency striding CNN network design from \cite{Sainath2015} named \texttt{conv-fstride4}.}
  \label{fig:nn_arch_cnn_fstride}
\end{figure}
\FloatBarrier
\noindent
\input{./4_nn/tables/tab_nn_arch_cnn_fstride4.tex}
The self designed \texttt{conv-jim} consists of two convolutional layers, where the first has an adaptive kernel size in the feature (freqnecy) dimension and is therefore striding only in frame (time) dimension.
The kernel width of the first convolutional filters is set to $20$, which represents much of the learned structure from the data, further $20$ frames are equal to \SI{200}{\milli\second}, which is a good time duration for vowels.
The second convolutional filter has a width of $5$ intended for temporal variations.
The \texttt{conv-jim} model is shown in \rfig{nn_arch_cnn_conv-jim} with footprint in \rtab{nn_arch_cnn_jim}.
\begin{figure}[!ht]
  \centering
    \includegraphics[height=0.2\textwidth]{./4_nn/figs/nn_arch_cnn_conv-jim.eps}
  \caption{Self designed frame (time) striding CNN named \texttt{conv-jim}.}
  \label{fig:nn_arch_cnn_conv-jim}
\end{figure}
\FloatBarrier
\noindent
\input{./4_nn/tables/tab_nn_arch_cnn_jim.tex}


% --
% GANs

\subsection{Generative Adversarial Neural Networks}\label{sec:nn_arch_adv}
Generative Adversarial Neural Networks (GAN), as already mentioned in \rsec{prev_nn_adv} are consisting of two separate neural network architectures, denoted as Discriminator (D) and Generator (G) network.
The G network is able to produce samples from the data distribution, while the D network has the role of discriminating between fake and real.
Being able to transfer the obtained weights from the training of the adversarial models, the layers parameters of the target network must coincide with the adversarial network layers.
The convolutional layer parameters of both D and G can be used, even if G performs a convolutional upsampling (transposed convolution) instead of usual convolution, however it is preferred to use frame-based normalization for the G network.

The major model tested with adversarial pre-training has the same convolutional layer structure as the \texttt{conv-jim} network and is therefore denoted as \texttt{adv-d-jim} shown in \rfig{nn_arch_adv_d_jim} and \texttt{adv-g-jim} in \rfig{nn_arch_adv_g_jim}.
\begin{figure}[!ht]
  \centering
    \includegraphics[height=0.2\textwidth]{./4_nn/figs/nn_arch_adv_d_jim.eps}
  \caption{Discriminator network named \texttt{adv-d-jim}.}
  \label{fig:nn_arch_adv_d_jim}
\end{figure}
\FloatBarrier
\noindent
\begin{figure}[!ht]
  \centering
    \includegraphics[height=0.23\textwidth]{./4_nn/figs/nn_arch_adv_g_jim.eps}
  \caption{Generator network named \texttt{adv-g-jim}.}
  \label{fig:nn_arch_adv_g_jim}
\end{figure}
\FloatBarrier
\noindent
Note that the number of operations are the same as in \rtab{nn_arch_cnn_jim}, except for the fully-connected layers.
The \texttt{adv-g-jim} model uses either the sigmoid or an identity (same output as input) activation function, depending whether the Mel Frequency Cepstral Coefficients (MFCC) are frame-based normalized or not.
If the MFCC are frame-based normalized the sigmoid activation function is used to produce outputs in the range of $[0, 1]$, which enhances the models training speed compared to the generation of samples that are not normalized.
%An overview of all models is shown in \rtab{nn_arch_overview} with abbreviations in \rtab{nn_arch_abbreviation}.
%\input{./4_nn/tables/tab_nn_arch_abbreviation.tex}
%\input{./4_nn/tables/tab_nn_arch.tex}


% --
% wavenets

\subsection{Wavenets}\label{sec:nn_arch_wavenet}
Wavenets were introduced in \cite{Oord2016} intended for speech generation on the processing of raw audio data.
In the paper it is mentioned that Wavenets can be used for Automatic Speech Recognition (ASR) tasks as well, though it is very sparsely described.
An implementation of a Wavenet can be found in \cite{Herrmann2018} (without class predictions) and motivated the following model structure.
A Wavenet residual block with an extension for class prediction is illustrated in \rfig{nn_arch_wavenet_block}.
\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.7\textwidth]{./4_nn/figs/nn_arch_wavenet_block.eps}
  \caption{Wavenet residual block \cite{Oord2016} with an extension of class prediction layers.}
  \label{fig:nn_arch_wavenet_block}
\end{figure}
\FloatBarrier
\noindent
One residual block incorporates few parameters, but a huge amount of operations, which are listed in \rtab{nn_arch_wavenet_block}
\input{./4_nn/tables/tab_nn_arch_wavenet_block}
Note that the dilated convolutional filters have a filter size of two with adjustable dilation parameter and that strides are merely done in the time dimension, because the input is a one-dimensional time signal.
The $1 \times 1$ convolutions are a special form of convolutional filters, that work the same way as usual convolutions, just with a filter size of one. 
The whole Wavenet architecture is composed of several Wavenet residual blocks with increasing dilation parameters for the convolutional layers.
The Wavenet architecture adaption with class prediction is shown in \rfig{nn_arch_wavenet_all}.
\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.9\textwidth]{./4_nn/figs/nn_arch_wavenet_all.eps}
  \caption{Wavenet architecture with class prediction extension.}
  \label{fig:nn_arch_wavenet_all}
\end{figure}
\FloatBarrier
\noindent
The whole structure with estimated number of operations is listed in \rtab{nn_arch_wavenet_whole}
\input{./4_nn/tables/tab_nn_arch_wavenet_whole}

