% --
% prev features

\section{Work on Audio Features for Speech Recognition}\label{sec:prev_features}
The feature extraction of audio signals is essential for an efficient data compression and extraction of relevant information.
This makes the extracted features suitable for further processing and classification tasks.
Not all audio signals should be handled in the same manner, as for instance, speech signals are very different from musical signals.
Music has its significant features in rhythm and pitch patterns, while speech does not specifically depend on those.
Speech can be spoken in different duration and pitch, depending on the speaker and the situation.
Therefore, speech signals are usually extracted to \emph{low-level features} that do not emphasize specific structures of duration and pitch.

One of the most popular low-level features used in speech recognition tasks, are the MFCCs introduced by \cite{Mermelstein1980}.
MFCCs are motivated by the physiological human hearing system by applying equidistant Mel-frequency bands, which is described in detail in \rsec{signal_mfcc}.
Other popular low-level features similar to the MFCCs are the Perceptual Linear Prediction (PLP) features \cite{Hermansky1987}.
PLPs have not been evaluated in this thesis yet it would have been interesting to compare their performance to MFCCs in the KWS task of speech commands.
An excellent summary and comparison between PLP and MFCC can be found in \cite{Hoenig2005}.

Recently, raw audio samples can be applied as input features to some special kind of neural networks, such as the Wavenet. 
However, the size of the input features is huge and there is no direct frequency correlation between those features as they merely present the waveform of the speech signal.