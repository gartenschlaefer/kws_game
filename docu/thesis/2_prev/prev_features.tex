% --
% prev features

\section{Work on Audio Features for Speech Recognition}\label{sec:prev_features}
The feature extraction of audio signals is important for an efficient data compression of raw audio samples and used for further processing or classification of those.
Not all audio signals should be handled the same way, as for instance speech signals are very different from musical signals.
In music the important features are rhythm and pitch, while speech does not use any of those specifically.
Speech can be spoken in different duration and frequency pitch, depending on the speaker and the situation.
Therefore speech signals are usually extracted to \emph{low-level features}, that do not incorporate specific structures of duration and pitch.

One of the most popular low-level features for speech recognition are the MFCCs, introduced by \cite{Mermelstein1980} in 1980.
MFCCs are motivated by the physiological human hearing system using equidistant mel-frequency bands and are described in detail in \rsec{signal_mfcc}.
Another popular low-level feature similar to MFCCs are Perceptual Linear Prediction (PLP) features introduced by \cite{Hermansky1987}.
PLPs were not evaluated in this thesis, but it would have been interesting to compare their performance to MFCCs in the KWS task of speech commands.
A good summary and comparison between PLP and MFCC can be found in \cite{Hoenig2005}.

Recently raw audio samples can be directly used as input features to some special kind of neural networks, such as the Wavenet, however the size of the input features is huge and there is no frequency correlation between the features except from the waveform they present.