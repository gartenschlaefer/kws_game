% --
% conclusion

\chapter{Conclusion}\label{sec:conclusion}
The conclusions obtained from the KWS task of speech commands applied in video games, are separated into its individual disciplines.
Those disciplines are as following the feature extraction of MFCCs and the key word onset detection, the evaluation of low computational CNNs with pre-training on weights from a separate training instance of GANs and the deployed KWS video game and its fast responses to input speech signals.
At the end of this chapter, the future work is presented.


% --
% featues

\section{Features}
\thesisStateReady
From the experiments in \rsec{exp_fs} certain constellations of MFCCs features and enhancements were evaluated.
It was observed that 12 cepstral coefficients were performing better than 32 cepstral coefficients on the used models and therefore the experiments were continued with 12 cepstral coefficients.
The enhancements of the MFCC features with delta and energy vectors, did not significantly improve the classification accuracies in consideration of the added computational footprint they require in the feature extraction and neural network model inference and therefore were left out.
The frame-based normalization yielded into worse accuracy scores of the test and validation set, but increased the noise invariance upon the test signals and reduced overfitting effects.
Further it enabled GANs to be trained faster and the use of valuable weights of convolutional layers from the Generator network as pre-trained weights for a conventional CNN.

The energy onset detection for key words, applied on the first cepstral coefficient of the MFCC features, was an efficient and accurate choice for the detection of key word onsets within the speech signal.
If there is no loud disturbance on the left or right hand-side of the energy pivot point of the spoken command within the speech signal and the neural network model is robust to shift invariance, there should be no problem with this simple onset method.


% --
% neural networks

\section{Neural Networks}
\thesisStateReady
The use of low computational CNN models composed of few layers enabled a good understanding on the learning of convolutional features maps during training, but could not reach the high accuracy achievements obtained by the sophisticated  benchmark models listed in \rsec{prev_kws_benchmark}. 
Still the evaluated models (apart from the Wavenet model) were sufficient for playing a video game with KWS providing enough accuracy in their prediction.
The preferred CNN model was the self designed \texttt{conv-jim} model with strides only in the frame dimension, it provided a good trade-off between accuracy and computational footprint.
The traditional model \texttt{conv-trad} achieved the best accuracy scores, but also required the most computational effort of all three models and it was more prone to overfitting effects during training.
The \texttt{conv-fstride} also performed well, even though its very small computational footprint, but often struggled with shift invariance.

It was shown, that GANs could be valuable for obtaining initial pre-trained weights for an equivalent CNN classifier with same convolutional layers.
The weights from the Generator (G) network were useful, even though an up-convolution instead of a normal convolution was performed.
The trade-off is, that a normalization scheme, such as the frame-based normalization, must be applied in order to make the weights of G applicable.
Nevertheless, with the pre-trained weights from G it was possible to increase the accuracies slightly.

In comparison to the benchmark models, the obtained accuracies on the test sets were significantly lower by about \SI{10}{\percent}.
But considering a lower amount of computations and a restricted time interval for the speech commands, the obtained accuracies were not that bad, though a \SI{100}{\percent} score on the \enquote{my dataset} would have been desirable.


% --
% game

\section{KWS Video Game}
\thesisStateReady
The time to process a single speech commands is one of the most important aspects in KWS video games, apart from the accurateness of the key word predictions.
The restriction of the time interval to \SI{500}{\milli\second} for a single key word, was a good decision to increase the fast responsiveness in playing the deployed KWS video game.
Including the prior and posterior buffer frames in the online system, a classification usually took about \SI{600}{\milli\second}.
Still it would be eligible if the detection of key words and triggering of actions were performed even faster, so that the playing experience could be increased further.

Considering the amount of computations for the feature extraction and the inference through the classifier, the deployed KWS Game was playable and had no lacks in frames, when played with 60 FPS.
Still a KWS system requires a significant amount of additional operations and can slow down a video game.
Even if a low computational model is used, there still remains the calculations necessary for the feature extraction, such as the extraction of MFCCs and those are quite heavy, as shown in \rsec{signal_mfcc_complexity}.

The overall playing experience with the augmented input control through the KWS system and the game mechanic of movable blocks, as described in \rsec{game_design_mechanics}, was a positive one.
Controlling elements in a game with voice is kind of magical and fun, as it is usually not that common to players, but can also end up in frustration when a speech command was wrongly classified or the responded actions happens not in time.
More game mechanics and level designs, that would increase the tension within the game would have been great, but as a proof of concept, the two levels with moveable blocks are a good starting point for more elaborate game mechanics and ideas using KWS.


% --
% future work

\section{Future Work}
\thesisStateReady
The goal in finding the most energy efficient model that obtains at the same time good accuracies for the KWS task of speech commands, is still a topic in future research, even though \cite{Zhang2017} and \cite{Peter2020} provide excellent solutions to this problem, it is desirable to understand the problem even further and derive a minimal model, where each layer can be understood and analyzed.
It is worth to evaluate the increase of the hop time from the used \SI{10}{\milli\second} to \SI{20}{\milli\second}, as applied in \cite{Peter2020}, this would reduce the computations approximately by half (both for the feature extraction and the classifier).
Further it would be interesting to evaluate an even smaller time interval, that should represent a key word below \SI{500}{\milli\second}, for a fast paced gaming experience.
Also it might be preferable to switch from a fixed sized input to a flexible one, so that no spoken key word will be missed, regardless of its duration.
This would enable the game to respond faster and allow the speaker to pronounces the key words with a short time duration.

Further research can be done on the value of the obtained weights from the Generator (G) model of a GAN training. 
An adversarial training scheme, as presented in \cite{Oezdenizci2020}, that consists of both a G model and a classical CNN model operating on the very same convolutional layers, would be extremely interesting, however one problem is the up-convolution performed by the G network, so that weight sharing is difficult to implement in this task.

Much future work has to be done on creating a Wavenet architecture, that is computationally light-weight and provides good classification accuracies, if that is even possible on raw audio samples.
Also the influence of game sounds during playing the video game was not evaluated and could be problematic if a high amount of audio feedback infers into the microphone input stream and alters the speech commands or even elicit them unintentionally.

In regards of video game designs with KWS, only the imagination restricts its possibilities and there are for sure countless great game ideas, that can use such a technique.
However it must be added that neural networks require large amounts of data and that every command word needs enough training samples.
This suggests solutions in the direction of phoneme based recognition, to be more flexible in the selection of command words.
A comparison between ASR and KWS in video games would therefore be a very interesting topic in upcoming research as well.